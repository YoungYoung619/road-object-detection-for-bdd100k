"""
Copyright (c) College of Mechatronics and Control Engineering, Shenzhen University.
All rights reserved.

Description :
A net use for Catch-Detection

Authorï¼šTeam Li
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import collections

import tensorflow as tf

import utils.net_tools as net_tools
from nets.backbone.mobilenet.mobilenet_v2 import mobilenet_v2
from nets.backbone.mobilenet.vgg_mbn_v2 import vgg_mobilenet_v2
from nets.backbone.mobilenet.mobilenet_v2 import training_scope
from nets.backbone.vgg import vgg_16
from nets.backbone.vgg import vgg_arg_scope
import config

from nets.attention_module import *

slim = tf.contrib.slim

backbone_maps = {"mobilenet_v2":mobilenet_v2,
                 "vgg_16": vgg_16,
                 'vgg_mbn_v2':vgg_mobilenet_v2}
arg_maps = {"mobilenet_v2":training_scope,
                 "vgg_16": vgg_arg_scope,
            'vgg_mbn_v2':training_scope}

class factory(object):
    """a class provide the net output"""
    def __init__(self, inputs, backbone_name, is_training, config_dict, dtype=tf.float32):
        """
        Args:
            inputs: imgs tensor with the shape [bs, h, w, c]
            backbone_name: a str indicates which backbone would be used.
            is_training:
            config: a dict indicate the config when building the whole net.
        """
        assert backbone_name in list(backbone_maps.keys())
        self. backbone_name = backbone_name
        self.is_training = is_training
        self.train_range = config_dict['train_range']

        ##build backbone
        with tf.variable_scope('backbone'):
            net = backbone_maps[backbone_name]
            with slim.arg_scope(arg_maps[backbone_name]()):
                end_points = net(inputs=inputs, is_training=is_training)

            backbone_feats = self.__feats_aug_block(end_points, config_dict['process_backbone_method'])
            self.backbone_feats = backbone_feats

        if is_training:

            ##build deconv and merge feats
            if config_dict['train_range'] is config.train_range.ALL:
                tf.logging.info('Building deconv net...')
                deconv_feats = self.__deconv_bone(backbone_feats, config_dict['deconv_method'],  is_training, dtype)
                self.deconv_feats  = deconv_feats
                tf.logging.info('Merging feats...')
                merge_feats = self.__merge_feats(backbone_feats, deconv_feats, config_dict['merge_method'],
                                                 attention_module=None)
                self.merge_feats = merge_feats

            ## build refine, det, clf net ##
            self.refine_out = self.__det_out(backbone_feats, is_training, scope='refine')

            if config_dict['train_range'] is config.train_range.ALL:
                self.clf_out = self.__clf_out(merge_feats, is_training, scope='clf')
                self.det_out = self.__det_out(merge_feats, is_training, scope='det')
        else: ## preditt or eval
            if config_dict['train_range'] is config.train_range.ALL:
                tf.logging.info('Building deconv net...')
                deconv_feats = self.__deconv_bone(backbone_feats, config_dict['deconv_method'], is_training, dtype)
                self.deconv_feats = deconv_feats
                tf.logging.info('Merging feats...')
                merge_feats = self.__merge_feats(backbone_feats, deconv_feats,
                                                 config_dict['merge_method'], attention_module=None)
                self.merge_feats = merge_feats

                ## build refine, det, clf net ##
                self.refine_out = self.__det_out(backbone_feats, is_training, scope='refine')
                self.clf_out = self.__clf_out(merge_feats, is_training, scope='clf')
                self.det_out = self.__det_out(merge_feats, is_training, scope='det')
            else:
                ## build refine, det, clf net ##
                self.refine_out = self.__det_out(backbone_feats, is_training, scope='refine')


    def __feats_aug_block(self, backbone_endpoints, method):
        """do some process in backbone endpoints
        Args:
            backbone_endpoints: endpoints of backbone
            method: the method of processing backbone endpoints
        Return:
            A dict: key---layer name
                    val---feature maps which would be used to train refine anchors
        """
        assert method in list(config.process_backbone_method.__members__.values())

        backbone_feats = collections.OrderedDict()

        if method is config.process_backbone_method.NONE:
            for index, feat_name in enumerate(config.extract_feat_name[self. backbone_name]):
                backbone_feats['layer_%s'%(str(index+1))] = backbone_endpoints[feat_name]
            return backbone_feats
        elif method is config.process_backbone_method.PREORDER_MSF:
            if self.backbone_name == 'mobilenet_v2':
                aug_extrated_feats_blocks = [['layer_4', 'layer_7'],
                                            ['layer_7', 'layer_11']]
                compress_ch_blocks = [[4, 16], [3, 12]]

                for index, feat_name in enumerate(config.extract_feat_name[self.backbone_name]):
                    if index < len(aug_extrated_feats_blocks):
                            aug_extrated_feats_block = aug_extrated_feats_blocks[index]
                            compress_ch_block = compress_ch_blocks[index]
                            s_feat = backbone_endpoints[feat_name]
                            aug_feat = []
                            for i, aug_extrated_feats_name in enumerate(aug_extrated_feats_block):
                                feat = backbone_endpoints[aug_extrated_feats_name]
                                ## h diff
                                h = feat.get_shape().as_list()[1]
                                s_h = s_feat.get_shape().as_list()[1]
                                h_diff = abs(h - (round(h/s_h))*s_h)
                                ## w diff
                                w = feat.get_shape().as_list()[2]
                                s_w = s_feat.get_shape().as_list()[2]
                                w_diff = abs(w - (round(w / s_w)) * s_w)

                                paddings = tf.constant([[0, 0], [h_diff, 0], [w_diff, 0], [0, 0]])
                                feat = tf.pad(feat, paddings, 'CONSTANT')

                                feat = slim.conv2d(feat, compress_ch_block[i], [1, 1], activation_fn=None)
                                feat = slim.batch_norm(feat, is_training=self.is_training, activation_fn=tf.nn.leaky_relu)

                                if round(h/s_h) > 1:
                                    feat = tf.space_to_depth(feat, block_size=round(h/s_h))
                                aug_feat.append(feat)
                            aug_feat.append(s_feat)
                            aug_feat = tf.concat(aug_feat, axis=-1)
                            backbone_feats['layer_%s' % (str(index + 1))] = se_block(aug_feat, name='aug_layer_%s' % (str(index + 1)))
                    else:
                        backbone_feats['layer_%s' % (str(index + 1))] = backbone_endpoints[feat_name]
                return  backbone_feats
            else:
                raise ValueError('Sorry, not support the method(%s) for mobilenet_v2 now ~_~!!' % str(method))
        else:
            raise ValueError('Not support the method(%s) now ~_~!!'%str(method))
            pass


    def __deconv_bone(self, backbone_feats, method, is_training, dtype, scope="deconv"):
        """build the upsample net
        Args:
            backbone_feats: a dict represents all the extracted feature maps from backbone
        Return:
            a list represents all the up-sample feature maps corresponding the input feat_layers
        """
        assert method in list(config.deconv_method.__members__.values())

        deconv_feats = collections.OrderedDict()
        feat_layers = list(backbone_feats.values())
        feat_layers.reverse()
        input = feat_layers[0]
        with tf.variable_scope(scope):
            for i in range(len(feat_layers)):
                with tf.variable_scope('block_%d' % (i + 1)):
                    if i == 0:
                        conv = slim.conv2d(input, input.get_shape().as_list()[-1], [1, 1], activation_fn=None)
                        input = slim.batch_norm(conv, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                        deconv_feats['layer_%d' % (i + 1)] = input
                    else:
                        if method == config.deconv_method.LEARN_HALF:
                            f_c = int(feat_layers[i].get_shape().as_list()[-1]/2)
                            i_c = int(input.get_shape().as_list()[-1])

                            ## learn_half ##
                            # de_weight = tf.get_variable('dweight_%d' % (i), shape=[1, 1, f_c, i_c],
                            #                            regularizer=tf.contrib.layers.l2_regularizer(1e-4),
                            #                            initializer=tf.truncated_normal_initializer(stddev=0.02))
                            de_weight = tf.get_variable('weight_%d' % (i), shape=[2, 2, f_c, i_c],
                                                        regularizer=tf.contrib.layers.l2_regularizer(1e-4),
                                                        initializer=tf.truncated_normal_initializer(stddev=0.02),
                                                        dtype=dtype)
                            #tf.summary.histogram(de_weight.name, de_weight)
                            shape = feat_layers[i].get_shape().as_list()
                            # output_shape  = ops.convert_to_tensor([-1, shape[1], shape[2], f_c])
                            upsample = tf.nn.conv2d_transpose(input, de_weight, output_shape=[shape[0], shape[1], shape[2], f_c],
                                                              strides=[1, 2, 2, 1], padding="SAME")

                            # learn_half = slim.conv2d(upsample, f_c, [3, 3], activation_fn=None)
                            # learn_half = slim.batch_norm(learn_half, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                            # learn_half = slim.conv2d(learn_half, f_c, [1, 1], activation_fn=None)
                            # learn_half = slim.batch_norm(learn_half, is_training=is_training, activation_fn=tf.nn.leaky_relu)

                            ## reuse half ##
                            # hw = learn_half.get_shape().as_list()[1:3]
                            hw = upsample.get_shape().as_list()[1:3]
                            reuse_half = tf.image.resize_images(input, hw)
                            reuse_half = tf.cast(reuse_half, dtype=dtype)
                            reuse_half = slim.conv2d(reuse_half, f_c, [1, 1], activation_fn=None)

                            input = tf.concat([upsample, reuse_half], axis=-1)
                            input = slim.batch_norm(input, is_training=is_training, activation_fn=tf.nn.leaky_relu)

                        elif method == config.deconv_method.LEARN_ALL:
                            f_c = int(feat_layers[i].get_shape().as_list()[-1])
                            i_c = int(input.get_shape().as_list()[-1])

                            # learn #
                            de_weight = tf.get_variable('weight_%d'%(i), shape=[2, 2, f_c, i_c],
                                                        regularizer=tf.contrib.layers.l2_regularizer(1e-4),
                                                        initializer=tf.truncated_normal_initializer(stddev=0.02),
                                                        dtype=dtype)
                            #tf.summary.histogram(de_weight.name, de_weight)
                            upsample = tf.nn.conv2d_transpose(input,de_weight,output_shape=tf.shape(feat_layers[i]),
                                                              strides=[1,2,2,1],padding="SAME")
                            #upsample = slim.conv2d_transpose(input, channel, [1, 1], 2, activation_fn=None)
                            # learn_all = slim.conv2d(upsample, f_c, [3, 3], activation_fn=None)
                            # learn_all = slim.batch_norm(learn_all, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                            # learn_all = slim.conv2d(learn_all, f_c, [1, 1], activation_fn=None)
                            input = slim.batch_norm(upsample, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                        else:
                            raise ValueError('Parameter "method(%s)" wrong'%str(method))
                        deconv_feats['layer_%d'%(i+1)] = input
        return deconv_feats


    def __merge_feats(self, backbone_feats, deconv_feats, method, attention_module=None, scope='merge'):
        """mix the features from backbone and deconvolution architecture
                Args:
                    down_endpoints: the dict-like extracted feature maps from backbone
                    up_endpoints: the dict-like extracted feature maps from deconvolution arichitecture
                    method: the feature merge method in net_config.py
                    attention_module: an attention module function
                    is_training: indicates training or not
                Return:
                    return the merge feature endpoints
                """
        assert method in list(config.merge_method.__members__.values())

        merge_feats = collections.OrderedDict()
        backbone_feats = list(backbone_feats.values())
        deconv_feats = list(deconv_feats.values())
        deconv_feats.reverse()
        i = 1
        with tf.variable_scope(scope):
            for up_feat, de_feat in zip(backbone_feats, deconv_feats):
                with tf.variable_scope("block_%d" % (i)):
                    if method == config.merge_method.CONCAT:
                        if attention_module != None:
                            aug_feat = attention_module(tf.concat([up_feat, de_feat], axis=-1), name="layer_%d" % (i))
                            merge_feats["layer_%d" % (i)] = aug_feat
                        else:
                            merge_feats["layer_%d" % (i)] = tf.concat([up_feat, de_feat], axis=-1)
                    elif method == config.merge_method.ADD:
                        if attention_module != None:
                            aug_feat = attention_module((up_feat + de_feat), name="layer_%d" % (i))
                            merge_feats["layer_%d" % (i)] = aug_feat
                        else:
                            merge_feats["layer_%d" % (i)] = up_feat + de_feat
                    else:
                        raise ValueError('parameter "method(%s)" wrong...'%str(method))
                    i += 1
        return merge_feats


    def __det_out(self, feats, is_training, scope="detection"):
        """ produce the detection tensor
        Args:
            feats: the dict-like output of merge feature maps or backbone feature maps
            is_training:
        Return:
            a list of tensor represents the offset from initial(or refine)anchor to ground-truth
            the tensor has the shape with [bs, feat_h, feat_w, n_anchor_one_layer, 4]
        """
        ## get the number of anchors in each layer' cell ##
        n_anchor_each_layer = net_tools.n_anchor_each_layer(self.backbone_name)

        ## build refine or det net ##
        with tf.variable_scope(scope):
            det_conv_config = [[128, 4 * n_anchor_each_layer[0]], [128, 4 * n_anchor_each_layer[1]],
                               [128, 4 * n_anchor_each_layer[2]], [128, 4 * n_anchor_each_layer[3]],
                               [128, 4 * n_anchor_each_layer[4]], [128, 4 * n_anchor_each_layer[5]]]

            det_out = []
            for i, tensor in enumerate(list(feats.values())):
                input = tensor
                with slim.arg_scope([slim.conv2d], weights_regularizer=slim.l2_regularizer(1e-4)):
                    with tf.variable_scope("block_%d" % (i + 1)):
                        for channel in det_conv_config[i]:
                            ## learn half ##
                            conv = slim.conv2d(input, channel, [1, 1], activation_fn=None)
                            conv = slim.batch_norm(conv, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                            conv = slim.conv2d(conv, channel, [3, 3], activation_fn=None)
                            output = slim.batch_norm(conv, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                            input = output
                    hw = output.get_shape().as_list()[1:3]
                    output = tf.reshape(output, shape=[-1] + hw + [n_anchor_each_layer[i], 4])
                    det_out.append(output)
        return det_out


    def __clf_out(self, feats, is_training, scope='classification'):
        """ produce the logits for each layer.
        Args:
            feats: the dict-like output of merge feature maps
        Return:
            a list of tensor represents the class score,the tensor has the shape
            with [bs, feat_h, feat_w, anchor_num, obj_num]
        """

        ## get the number of anchors in each layer' cell ##
        n_anchor_each_layer = net_tools.n_anchor_each_layer(self.backbone_name)

        with tf.variable_scope(scope):
            clf_conv_config = [[128, config.total_obj_n * n_anchor_each_layer[0]], [128, config.total_obj_n * n_anchor_each_layer[1]],
                               [128, config.total_obj_n * n_anchor_each_layer[2]], [128, config.total_obj_n * n_anchor_each_layer[3]],
                               [128, config.total_obj_n * n_anchor_each_layer[4]], [128, config.total_obj_n * n_anchor_each_layer[5]]]
            clf_out = []
            for i, tensor in enumerate(list(feats.values())):
                input = tensor
                with slim.arg_scope([slim.conv2d], weights_regularizer=slim.l2_regularizer(1e-4)):
                    with tf.variable_scope("block_%d" % (i + 1)):
                        for channel in clf_conv_config[i]:
                            conv = slim.conv2d(input, channel, [1, 1], activation_fn=None)
                            conv = slim.batch_norm(conv, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                            conv = slim.conv2d(conv, channel, [3, 3], activation_fn=None)
                            output = slim.batch_norm(conv, is_training=is_training, activation_fn=tf.nn.leaky_relu)
                            input = output
                    hw = output.get_shape().as_list()[1:3]
                    output = tf.reshape(output, shape=[-1] + hw + [n_anchor_each_layer[i], config.total_obj_n])
                    clf_out.append(output)  ##without softmax
        return clf_out

    def get_output(self):
        """get output
        Args:
            if train_range is REFINE, return refine_out
            if train_range is ALL, return refine_out, det_out, clf_out
        """
        if self.is_training:
            if self.train_range is config.train_range.ALL:
                return self.refine_out, self.det_out, self.clf_out
            elif self.train_range is config.train_range.REFINE:
                return self.refine_out
            else:
                raise ValueError('Error')
        else:
            if self.train_range is config.train_range.ALL:
                return self.refine_out, self.det_out, self.clf_out
            elif self.train_range is config.train_range.REFINE:
                return self.refine_out
            else:
                raise ValueError('Error')

if __name__ == '__main__':
    imgs = tf.placeholder(dtype=tf.float16, shape=[None, 418, 418, 3])
    config_dict = {'train_range':config.train_range.ALL,
                   'process_backbone_method': config.process_backbone_method.PREORDER_MSF,
                   'deconv_method':config.deconv_method.LEARN_HALF,
                   'merge_method':config.merge_method.ADD}
    net = factory(inputs=imgs, backbone_name='mobilenet_v2', is_training=True, config_dict=config_dict)
    b = net.backbone_feats
    c = net.deconv_feats
    d = net.merge_feats
    refine_out, det_out, clf_out = net.get_output()
    pass